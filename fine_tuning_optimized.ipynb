{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Model\n",
    "\n",
    "Let's teach our text to image generator what my dog looks like.  In case you've"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU7NuMAA2drw",
    "outputId": "2e5ad228-fdf6-4828-e558-8c8c323ffdad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 17 19:53:04 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   31C    P8    25W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "NVIDIA A10G, 23028 MiB, 22723 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnTMyW41cC1E"
   },
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade accelerate transformers ftfy\n",
    "!pip install -q git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-17 19:53:16--  https://rhods-public.s3.amazonaws.com/src/xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl\n",
      "Resolving rhods-public.s3.amazonaws.com (rhods-public.s3.amazonaws.com)... 16.182.67.57, 54.231.140.137, 54.231.234.177, ...\n",
      "Connecting to rhods-public.s3.amazonaws.com (rhods-public.s3.amazonaws.com)|16.182.67.57|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 127729734 (122M) [binary/octet-stream]\n",
      "Saving to: ‘xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl’\n",
      "\n",
      "xformers-0.0.21.dev 100%[===================>] 121.81M  62.1MB/s    in 2.0s    \n",
      "\n",
      "2023-08-17 19:53:19 (62.1 MB/s) - ‘xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl’ saved [127729734/127729734]\n",
      "\n",
      "Processing ./xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.9/site-packages (from xformers==0.0.21.dev584) (1.24.4)\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/app-root/lib/python3.9/site-packages (from xformers==0.0.21.dev584) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch==1.13.1->xformers==0.0.21.dev584) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch==1.13.1->xformers==0.0.21.dev584) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch==1.13.1->xformers==0.0.21.dev584) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch==1.13.1->xformers==0.0.21.dev584) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch==1.13.1->xformers==0.0.21.dev584) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->xformers==0.0.21.dev584) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->xformers==0.0.21.dev584) (0.38.4)\n",
      "xformers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wget https://rhods-public.s3.amazonaws.com/src/xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl -O xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl\n",
    "!pip install xformers-0.0.21.dev584-cp39-cp39-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                      0.21.0\n",
      "diffusers                       0.21.0.dev0\n",
      "ftfy                            6.1.1\n",
      "Jinja2                          3.1.2\n",
      "tensorboard                     2.11.2\n",
      "tensorboard-data-server         0.6.1\n",
      "tensorboard-plugin-wit          1.8.1\n",
      "torch                           1.13.1\n",
      "torchvision                     0.14.1\n",
      "transformers                    4.31.0\n",
      "xformers                        0.0.21.dev584\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -e torch -e torchvision -e diffusers -e accelerate -e torchvision -e transformers -e ftfy -e tensorboard -e Jinja2 -e xformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0NV324ZcL9L"
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxg0y5MBudmd",
    "outputId": "1c67fe1f-5652-439c-abae-920824533765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights will be saved at /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog\n",
      "MODEL_NAME=runwayml/stable-diffusion-v1-5\n",
      "Training data located in /opt/app-root/src/text-to-image-demo/optimized/data/redhat-dog\n",
      "Instance Prompt = photo of a rhteddy dog\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "VERSION = \"optimized\"\n",
    "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), f\"{VERSION}/stable_diffusion_weights/redhat-dog\")\n",
    "DATA_DIR = os.path.join(os.getcwd(), f\"{VERSION}/data\")\n",
    "INSTANCE_DIR = os.path.join(DATA_DIR, \"redhat-dog\")\n",
    "CLASS_DIR = os.path.join(DATA_DIR, \"dog\")\n",
    "INSTANCE_PROMPT = \"photo of a rhteddy dog\"\n",
    "CLASS_PROMPT = \"a photo of dog\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(INSTANCE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Weights will be saved at {OUTPUT_DIR}\")\n",
    "print(f\"MODEL_NAME={MODEL_NAME}\")\n",
    "print(f\"Training data located in {INSTANCE_DIR}\")\n",
    "print(f\"Instance Prompt = {INSTANCE_PROMPT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn5ILIyDJIcX"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "url = \"https://rhods-public.s3.amazonaws.com/sample-data/images/redhat-dog.tar.gz\"\n",
    "output = os.path.join(DATA_DIR, \"redhat-dog.tar.gz\")\n",
    "urllib.request.urlretrieve(url, output)\n",
    "\n",
    "file = tarfile.open(output)\n",
    "file.extractall(DATA_DIR)\n",
    "file.close ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /opt/app-root/src/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    }
   ],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-17 19:53:25--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 55732 (54K) [text/plain]\n",
      "Saving to: ‘train_dreambooth.py’\n",
      "\n",
      "train_dreambooth.py 100%[===================>]  54.43K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-08-17 19:53:26 (56.7 MB/s) - ‘train_dreambooth.py’ saved [55732/55732]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train_dreambooth.py https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runwayml/stable-diffusion-v1-5\n",
      "/opt/app-root/src/text-to-image-demo/optimized/data/redhat-dog\n",
      "/opt/app-root/src/text-to-image-demo/optimized/data/dog\n",
      "/opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog\n",
      "photo of a rhteddy dog\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "08/17/2023 19:53:30 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]{'projection_class_embeddings_input_dim', 'addition_embed_type', 'num_attention_heads', 'timestep_post_act', 'upcast_attention', 'cross_attention_norm', 'transformer_layers_per_block', 'only_cross_attention', 'mid_block_only_cross_attention', 'class_embeddings_concat', 'time_embedding_dim', 'class_embed_type', 'resnet_out_scale_factor', 'dual_cross_attention', 'resnet_skip_time_act', 'encoder_hid_dim_type', 'time_embedding_type', 'use_linear_projection', 'conv_in_kernel', 'attention_type', 'time_embedding_act_fn', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'addition_time_embed_dim', 'mid_block_type', 'num_class_embeds', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.\n",
      "Loaded unet as UNet2DConditionModel from `unet` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  17%|██▏          | 1/6 [00:00<00:03,  1.40it/s]{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  33%|████▎        | 2/6 [00:00<00:01,  2.55it/s]Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...:  83%|██████████▊  | 5/6 [00:01<00:00,  5.85it/s]{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loading pipeline components...: 100%|█████████████| 6/6 [00:01<00:00,  5.30it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "08/17/2023 19:53:32 - INFO - __main__ - Number of class images to sample: 200.\n",
      "Generating class images: 100%|██████████████████| 50/50 [11:43<00:00, 14.06s/it]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'clip_sample_range', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'sample_max_value', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'projection_class_embeddings_input_dim', 'addition_embed_type', 'num_attention_heads', 'timestep_post_act', 'upcast_attention', 'cross_attention_norm', 'transformer_layers_per_block', 'only_cross_attention', 'mid_block_only_cross_attention', 'class_embeddings_concat', 'time_embedding_dim', 'class_embed_type', 'resnet_out_scale_factor', 'dual_cross_attention', 'resnet_skip_time_act', 'encoder_hid_dim_type', 'time_embedding_type', 'use_linear_projection', 'conv_in_kernel', 'attention_type', 'time_embedding_act_fn', 'encoder_hid_dim', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'addition_time_embed_dim', 'mid_block_type', 'num_class_embeds', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.\n",
      "08/17/2023 20:05:18 - INFO - __main__ - ***** Running training *****\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Num examples = 200\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Num batches each epoch = 200\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Num Epochs = 5\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "08/17/2023 20:05:18 - INFO - __main__ -   Total optimization steps = 1000\n",
      "Steps:  50%|██████      | 500/1000 [07:23<07:23,  1.13it/s, loss=0.765, lr=5e-6]08/17/2023 20:12:42 - INFO - accelerate.accelerator - Saving current state to /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500\n",
      "Configuration saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500/unet/config.json\n",
      "Model weights saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "08/17/2023 20:13:16 - INFO - accelerate.checkpointing - Optimizer state saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500/optimizer.bin\n",
      "08/17/2023 20:13:16 - INFO - accelerate.checkpointing - Scheduler state saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500/scheduler.bin\n",
      "08/17/2023 20:13:16 - INFO - accelerate.checkpointing - Random states saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500/random_states_0.pkl\n",
      "08/17/2023 20:13:16 - INFO - __main__ - Saved state to /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-500\n",
      "Steps: 100%|███████████| 1000/1000 [15:22<00:00,  1.14it/s, loss=0.167, lr=5e-6]08/17/2023 20:20:40 - INFO - accelerate.accelerator - Saving current state to /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000\n",
      "Configuration saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000/unet/config.json\n",
      "Model weights saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000/unet/diffusion_pytorch_model.safetensors\n",
      "08/17/2023 20:21:16 - INFO - accelerate.checkpointing - Optimizer state saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000/optimizer.bin\n",
      "08/17/2023 20:21:16 - INFO - accelerate.checkpointing - Scheduler state saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000/scheduler.bin\n",
      "08/17/2023 20:21:16 - INFO - accelerate.checkpointing - Random states saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000/random_states_0.pkl\n",
      "08/17/2023 20:21:16 - INFO - __main__ - Saved state to /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/checkpoint-1000\n",
      "Steps: 100%|███████████| 1000/1000 [15:57<00:00,  1.14it/s, loss=0.289, lr=5e-6]{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...:  29%|███▋         | 2/7 [00:01<00:03,  1.51it/s]\u001b[A{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:01<00:00,  4.90it/s]\u001b[A\n",
      "{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n",
      "Configuration saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/vae/config.json\n",
      "Model weights saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/vae/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/unet/config.json\n",
      "Model weights saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/unet/diffusion_pytorch_model.safetensors\n",
      "Configuration saved in /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog/scheduler/scheduler_config.json\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/app-root/src/text-to-image-demo/train_dreambooth.py\", line 1387, in <module>\n",
      "    main(args)\n",
      "  File \"/opt/app-root/src/text-to-image-demo/train_dreambooth.py\", line 1363, in main\n",
      "    pipeline.save_pretrained(args.output_dir)\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\", line 655, in save_pretrained\n",
      "    save_method(os.path.join(save_directory, pipeline_component_name), **save_kwargs)\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/transformers/modeling_utils.py\", line 1845, in save_pretrained\n",
      "    safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={\"format\": \"pt\"})\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/safetensors/torch.py\", line 282, in save_file\n",
      "    serialize_file(_flatten(tensors), filename, metadata=metadata)\n",
      "safetensors_rust.SafetensorError: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })\n",
      "Steps: 100%|███████████| 1000/1000 [17:05<00:00,  1.03s/it, loss=0.289, lr=5e-6]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/app-root/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/accelerate/commands/launch.py\", line 979, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/opt/app-root/lib64/python3.9/site-packages/accelerate/commands/launch.py\", line 628, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/app-root/bin/python3.9', 'train_dreambooth.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--instance_data_dir=/opt/app-root/src/text-to-image-demo/optimized/data/redhat-dog', '--class_data_dir=/opt/app-root/src/text-to-image-demo/optimized/data/dog', '--output_dir=/opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog', '--with_prior_preservation', '--prior_loss_weight=1.0', '--instance_prompt=photo of a rhteddy dog', '--class_prompt=a photo of dog', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--num_class_images=200', '--max_train_steps=1000', '--enable_xformers_memory_efficient_attention']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!echo $MODEL_NAME \n",
    "!echo $INSTANCE_DIR\n",
    "!echo $CLASS_DIR\n",
    "!echo $OUTPUT_DIR\n",
    "!echo $INSTANCE_PROMPT\n",
    "\n",
    "!accelerate launch train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --class_data_dir=$CLASS_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "  --instance_prompt=\"$INSTANCE_PROMPT\" \\\n",
    "  --class_prompt=\"$CLASS_PROMPT\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=5e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --num_class_images=200 \\\n",
    "  --max_train_steps=1000 \\\n",
    "  --enable_xformers_memory_efficient_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToNG4fd_dTbF"
   },
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gW15FjffdTID",
    "outputId": "facb93da-ac48-4a3b-a53a-0a57c15aa6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error no file named model_index.json found in directory /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline\n\u001b[0;32m----> 4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py:954\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     cached_folder \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m--> 954\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# pop out \"_ignore_files\" as it is only needed for download\u001b[39;00m\n\u001b[1;32m    957\u001b[0m config_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ignore_files\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/diffusers/configuration_utils.py:364\u001b[0m, in \u001b[0;36mConfigMixin.load_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pretrained_model_name_or_path, subfolder, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_name)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m         )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Error no file named model_index.json found in directory /opt/app-root/src/text-to-image-demo/optimized/stable_diffusion_weights/redhat-dog."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(OUTPUT_DIR)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline.to(device)\n",
    "pipeline.enable_xformers_memory_efficient_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561,
     "referenced_widgets": [
      "eca04bb8e40f49c7869f00512e0767a6",
      "180888618e5a4d5d9c5bace5ef15c21a",
      "582d3b3efd32478da7754bf2cb5530c3",
      "b9f236f54bf640f791c17beb11c95c66",
      "0cee055de82f4a4d8019e90d5ed1dfbb",
      "da70b684ad3f44789cf0f213708f5da5",
      "83954ef920464529acf6015cb9d31693",
      "28491b57195048b99c3714b60c8a25c2",
      "b662d5f27cd5413db237b78bd137cae7",
      "9b8392f2d04e476ea94e7c5889d9fdd7",
      "e3116fa65f6b4abcbc9ce7e61bdfb45f"
     ]
    },
    "id": "K6xoHWSsbcS3",
    "outputId": "0166db1f-2d4f-411c-f18c-2b07f0cd163c"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch import autocast\n",
    "\n",
    "IMG_DIR = os.path.join(os.getcwd(), f\"{VERSION}/generated-images/{date_string}\")\n",
    "prompt = \"photo of a rhteddy dog on the beach\"\n",
    "negative_prompt = \"\"\n",
    "num_samples = 6\n",
    "guidance_scale = 7.5\n",
    "num_inference_steps = 200\n",
    "height = 512\n",
    "width = 512\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "generator.seed()\n",
    "\n",
    "with autocast(device.type), torch.inference_mode():\n",
    "    images = pipeline(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_samples,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=generator\n",
    "    ).images\n",
    "\n",
    "\n",
    "date = datetime.now()\n",
    "date_string = date.strftime('%Y%m%d%H%M%S')\n",
    "IMG_DIR = f\"./{VERSION}/generated-images/{date_string}\"\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    img.save(os.path.join(IMG_DIR, f\"{i}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "directory = IMG_DIR\n",
    "images = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img = Image.open(os.path.join(directory, filename))\n",
    "        images.append(img)\n",
    "\n",
    "num_show = min(len(images), 12)\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(images) / n_cols)\n",
    "scale = 4\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * scale, n_rows * scale),  gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        axs[i, j].axis('off')\n",
    "        x = i * n_cols + j\n",
    "        if x < len(images):\n",
    "            axs[i, j].imshow(images[x])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cee055de82f4a4d8019e90d5ed1dfbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "180888618e5a4d5d9c5bace5ef15c21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da70b684ad3f44789cf0f213708f5da5",
      "placeholder": "​",
      "style": "IPY_MODEL_83954ef920464529acf6015cb9d31693",
      "value": "100%"
     }
    },
    "195e8f3e983342d9b7227ee9e4461153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d7ea19cc56a43c68df69bcc9655b8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a58f6b987c9f4f5e9a1b0a73c4ae549e",
       "IPY_MODEL_d2740a085b95416b88fa742e058402be",
       "IPY_MODEL_8252ddb68924432b87a1083b7e6aaa6e"
      ],
      "layout": "IPY_MODEL_e7113dfd596d4ecc8b1ebd76ee979d92"
     }
    },
    "28491b57195048b99c3714b60c8a25c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "582d3b3efd32478da7754bf2cb5530c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28491b57195048b99c3714b60c8a25c2",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b662d5f27cd5413db237b78bd137cae7",
      "value": 200
     }
    },
    "6eacdf7c06d041218c0b96745106e712": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "746ae93e85b94b0c9371e1dff99fc620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8252ddb68924432b87a1083b7e6aaa6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe3f23ff7b8b46938a53c5e1bfdbaaca",
      "placeholder": "​",
      "style": "IPY_MODEL_916a795f943e475cbdc41ed25dab3deb",
      "value": " 200/200 [00:31&lt;00:00,  6.29it/s]"
     }
    },
    "83954ef920464529acf6015cb9d31693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "916a795f943e475cbdc41ed25dab3deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b8392f2d04e476ea94e7c5889d9fdd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58f6b987c9f4f5e9a1b0a73c4ae549e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be1ef96102b545a782d54b3dfd698696",
      "placeholder": "​",
      "style": "IPY_MODEL_746ae93e85b94b0c9371e1dff99fc620",
      "value": "100%"
     }
    },
    "b662d5f27cd5413db237b78bd137cae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9f236f54bf640f791c17beb11c95c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8392f2d04e476ea94e7c5889d9fdd7",
      "placeholder": "​",
      "style": "IPY_MODEL_e3116fa65f6b4abcbc9ce7e61bdfb45f",
      "value": " 200/200 [00:31&lt;00:00,  6.34it/s]"
     }
    },
    "be1ef96102b545a782d54b3dfd698696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2740a085b95416b88fa742e058402be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eacdf7c06d041218c0b96745106e712",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_195e8f3e983342d9b7227ee9e4461153",
      "value": 200
     }
    },
    "da70b684ad3f44789cf0f213708f5da5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3116fa65f6b4abcbc9ce7e61bdfb45f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7113dfd596d4ecc8b1ebd76ee979d92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eca04bb8e40f49c7869f00512e0767a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_180888618e5a4d5d9c5bace5ef15c21a",
       "IPY_MODEL_582d3b3efd32478da7754bf2cb5530c3",
       "IPY_MODEL_b9f236f54bf640f791c17beb11c95c66"
      ],
      "layout": "IPY_MODEL_0cee055de82f4a4d8019e90d5ed1dfbb"
     }
    },
    "fe3f23ff7b8b46938a53c5e1bfdbaaca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
