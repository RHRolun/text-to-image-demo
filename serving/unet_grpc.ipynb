{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73046ff",
   "metadata": {},
   "source": [
    "# GRPC Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e7e73-24cb-4f03-9491-a6edcc24f0cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c80d0a-2e7f-4bfb-a004-db1ada9969f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpcio                          1.56.0\n",
      "grpcio-tools                    1.33.2\n",
      "protobuf                        3.20.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -e grpcio -e protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a1896a-efc5-447f-b2a3-365790936aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio==1.56.0 in /opt/app-root/lib/python3.9/site-packages (1.56.0)\n",
      "Requirement already satisfied: grpcio-tools==1.33.2 in /opt/app-root/lib/python3.9/site-packages (1.33.2)\n",
      "Requirement already satisfied: protobuf==3.20.3 in /opt/app-root/lib/python3.9/site-packages (3.20.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install grpcio==1.56.0 grpcio-tools==1.33.2 protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b986bc-07cb-430c-b16a-56d4cc4f675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpcio                          1.56.0\n",
      "grpcio-tools                    1.33.2\n",
      "protobuf                        3.20.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -e grpcio -e protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d17b252-7827-4cae-adb0-f98c9d80bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_host = 'modelmesh-serving'\n",
    "grpc_port = 8033\n",
    "\n",
    "textencoder_model_name = 'textencoder'\n",
    "unet_model_name = 'unet'\n",
    "vaeencoder_model_name = 'vaeencoder'\n",
    "vaedecoder_model_name = 'vaedecoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269da9e-5683-4531-9a3f-a1cdad42e3af",
   "metadata": {},
   "source": [
    "### Inspecting the gRPC Endpoint\n",
    "\n",
    "Let's check out the gRPC endpoint's model metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545aa5f4-356f-4e70-b7e6-cd352a68927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"unet__isvc-6ee2a9ae97\"\n",
      "versions: \"1\"\n",
      "platform: \"onnxruntime_onnx\"\n",
      "inputs {\n",
      "  name: \"encoder_hidden_states\"\n",
      "  datatype: \"FP32\"\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "  shape: 768\n",
      "}\n",
      "inputs {\n",
      "  name: \"timestep\"\n",
      "  datatype: \"INT64\"\n",
      "  shape: -1\n",
      "  shape: 1\n",
      "}\n",
      "inputs {\n",
      "  name: \"sample\"\n",
      "  datatype: \"FP32\"\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "}\n",
      "outputs {\n",
      "  name: \"out_sample\"\n",
      "  datatype: \"FP32\"\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "  shape: -1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import grpc_predict_v2_pb2\n",
    "import grpc_predict_v2_pb2_grpc\n",
    "\n",
    "\n",
    "channel = grpc.insecure_channel(f\"{grpc_host}:{grpc_port}\")\n",
    "stub = grpc_predict_v2_pb2_grpc.GRPCInferenceServiceStub(channel)\n",
    "\n",
    "# request = grpc_predict_v2_pb2.ModelMetadataRequest(name=textencoder_model_name)\n",
    "# response = stub.ModelMetadata(request)\n",
    "# print(response)\n",
    "\n",
    "request = grpc_predict_v2_pb2.ModelMetadataRequest(name=unet_model_name)\n",
    "response = stub.ModelMetadata(request)\n",
    "print(response)\n",
    "\n",
    "# request = grpc_predict_v2_pb2.ModelMetadataRequest(name=vaeencoder_model_name)\n",
    "# response = stub.ModelMetadata(request)\n",
    "# print(response)\n",
    "\n",
    "# request = grpc_predict_v2_pb2.ModelMetadataRequest(name=vaedecoder_model_name)\n",
    "# response = stub.ModelMetadata(request)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5affbf-36c3-4e17-9788-5fc0904de143",
   "metadata": {},
   "source": [
    "### Request Function\n",
    "\n",
    "Builds and submits our gRPC request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c1d001-ff99-414a-95d4-5729d5849298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def unet_grpc_request(encoder_hidden_states, timestep, sample):\n",
    "    inputs = []\n",
    "    inputs.append(grpc_predict_v2_pb2.ModelInferRequest().InferInputTensor())\n",
    "    inputs[0].name = \"encoder_hidden_states\"\n",
    "    inputs[0].datatype = \"FP32\"\n",
    "    inputs[0].shape.extend([2, 77, 768])\n",
    "    arr = encoder_hidden_states.flatten()\n",
    "    inputs[0].contents.fp32_contents.extend(arr)\n",
    "\n",
    "    inputs.append(grpc_predict_v2_pb2.ModelInferRequest().InferInputTensor())\n",
    "    inputs[1].name = \"timestep\"\n",
    "    inputs[1].datatype = \"INT64\"\n",
    "    inputs[1].shape.extend([2, 1])\n",
    "    arr = timestep.flatten()\n",
    "    inputs[1].contents.int64_contents.extend(arr)\n",
    "\n",
    "    inputs.append(grpc_predict_v2_pb2.ModelInferRequest().InferInputTensor())\n",
    "    inputs[2].name = \"sample\"\n",
    "    inputs[2].datatype = \"FP32\"\n",
    "    inputs[2].shape.extend([2, 4, 64, 64])\n",
    "    arr = sample.flatten()\n",
    "    inputs[2].contents.fp32_contents.extend(arr)\n",
    "\n",
    "    request = grpc_predict_v2_pb2.ModelInferRequest()\n",
    "    request.model_name = unet_model_name\n",
    "    request.inputs.extend(inputs)\n",
    "\n",
    "    response = stub.ModelInfer(request)\n",
    "    out_sample = np.frombuffer(response.raw_output_contents[0], dtype=np.float32)\n",
    "\n",
    "    return torch.tensor(out_sample.reshape([-1, 4, 64, 64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b1015-28b0-4d60-bc17-7b30326b97bc",
   "metadata": {},
   "source": [
    "### Run the Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12947866-e0f5-4c72-ba9a-04229b1af990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "latent_model_input = np.load(\"latent_model_input.npy\")\n",
    "text_embeddings = np.load(\"text_embeddings.npy\")\n",
    "timestep = np.load(\"t.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002cd999-408f-478f-878a-d0ffea687583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "out_sample = unet_grpc_request(text_embeddings, torch.tensor([1, 1]), latent_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129a81ea-f3aa-4ecd-9a12-3f7cebd4816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([2, 4, 64, 64])\n",
      "tensor([[[[-0.1189, -0.1315, -0.1506,  ..., -0.3761,  0.3015,  0.1556],\n",
      "          [ 0.1426,  0.1699,  0.1616,  ...,  0.3701, -0.1057,  0.4558],\n",
      "          [-0.1506, -0.0131, -0.3082,  ..., -0.1181, -0.4185, -0.4856],\n",
      "          ...,\n",
      "          [ 0.0302, -0.0854, -0.3603,  ..., -0.4310, -0.0114, -0.0228],\n",
      "          [ 0.1836, -0.2188, -0.2780,  ...,  0.4091, -0.1020,  0.3825],\n",
      "          [ 0.1844, -0.0516,  0.2451,  ..., -0.8658, -0.3165,  0.3079]],\n",
      "\n",
      "         [[ 0.4641,  0.2499, -0.0863,  ...,  0.1582, -0.1716,  0.3040],\n",
      "          [-0.1720, -0.3084, -0.0990,  ...,  0.0532,  0.2248,  0.3627],\n",
      "          [ 0.0750, -0.0261,  0.3229,  ..., -0.0181, -0.3284, -0.0850],\n",
      "          ...,\n",
      "          [-0.2300,  0.1531,  0.1063,  ..., -0.2409, -0.1880, -0.3696],\n",
      "          [-0.3809,  0.0884,  0.1340,  ..., -0.3222,  0.1739, -0.1053],\n",
      "          [-0.0616,  0.2329, -0.0213,  ..., -0.0629, -0.1140, -0.0694]],\n",
      "\n",
      "         [[ 0.0459, -0.0218, -0.0303,  ...,  0.1230, -0.4340,  0.9760],\n",
      "          [-0.0629,  0.0456, -0.0374,  ..., -0.2647, -0.3111,  0.1210],\n",
      "          [-0.0603, -0.1621, -0.3260,  ..., -0.1670, -0.2123,  0.3321],\n",
      "          ...,\n",
      "          [-0.1025,  0.0968,  0.1109,  ..., -0.2387, -0.3767, -0.3532],\n",
      "          [-0.2159,  0.0168, -0.0705,  ..., -0.3640,  0.3875, -0.3456],\n",
      "          [-0.1114,  0.2341,  0.0400,  ...,  0.4274, -0.1495, -0.1612]],\n",
      "\n",
      "         [[-0.1404, -0.1175,  0.1734,  ...,  0.4634,  0.3762, -0.7041],\n",
      "          [-0.5509,  0.2258, -0.2719,  ..., -0.5625,  0.4040, -0.3714],\n",
      "          [-0.2277,  0.0632,  0.0197,  ..., -0.1635,  0.2027,  0.1470],\n",
      "          ...,\n",
      "          [-0.0714,  0.0671, -0.4558,  ...,  0.1704, -0.1106, -0.0210],\n",
      "          [ 0.3447,  0.3501, -0.1910,  ..., -0.2800,  0.0289, -0.4134],\n",
      "          [ 0.1086,  0.1624, -0.2729,  ...,  0.5096, -0.0310, -0.3315]]],\n",
      "\n",
      "\n",
      "        [[[-0.1088, -0.1305, -0.1459,  ..., -0.3631,  0.2874,  0.1472],\n",
      "          [ 0.1429,  0.1781,  0.1658,  ...,  0.3760, -0.0842,  0.4447],\n",
      "          [-0.1534, -0.0166, -0.3141,  ..., -0.1144, -0.4239, -0.4711],\n",
      "          ...,\n",
      "          [ 0.0400, -0.1001, -0.3494,  ..., -0.4209, -0.0130, -0.0219],\n",
      "          [ 0.1869, -0.2233, -0.2771,  ...,  0.4103, -0.0987,  0.3922],\n",
      "          [ 0.1881, -0.0570,  0.2453,  ..., -0.8808, -0.3173,  0.2991]],\n",
      "\n",
      "         [[ 0.4582,  0.2626, -0.0789,  ...,  0.1614, -0.1719,  0.2992],\n",
      "          [-0.1666, -0.3066, -0.0993,  ...,  0.0534,  0.2240,  0.3698],\n",
      "          [ 0.0750, -0.0301,  0.3336,  ..., -0.0130, -0.3273, -0.0783],\n",
      "          ...,\n",
      "          [-0.2347,  0.1539,  0.1031,  ..., -0.2414, -0.1867, -0.3704],\n",
      "          [-0.3763,  0.0818,  0.1335,  ..., -0.3303,  0.1580, -0.1084],\n",
      "          [-0.0577,  0.2253, -0.0022,  ..., -0.0664, -0.1049, -0.0697]],\n",
      "\n",
      "         [[ 0.0461, -0.0135, -0.0202,  ...,  0.1241, -0.4366,  0.9781],\n",
      "          [-0.0661,  0.0459, -0.0506,  ..., -0.2681, -0.3011,  0.1310],\n",
      "          [-0.0597, -0.1593, -0.3208,  ..., -0.1777, -0.2165,  0.3352],\n",
      "          ...,\n",
      "          [-0.1112,  0.1116,  0.1103,  ..., -0.2279, -0.3746, -0.3583],\n",
      "          [-0.2226,  0.0266, -0.0715,  ..., -0.3625,  0.3853, -0.3388],\n",
      "          [-0.1066,  0.2265,  0.0540,  ...,  0.4319, -0.1430, -0.1645]],\n",
      "\n",
      "         [[-0.1417, -0.1169,  0.1683,  ...,  0.4511,  0.3951, -0.7074],\n",
      "          [-0.5427,  0.2243, -0.2696,  ..., -0.5472,  0.3976, -0.3701],\n",
      "          [-0.2309,  0.0761,  0.0298,  ..., -0.1696,  0.2128,  0.1452],\n",
      "          ...,\n",
      "          [-0.0694,  0.0733, -0.4620,  ...,  0.1732, -0.1011, -0.0127],\n",
      "          [ 0.3322,  0.3410, -0.1818,  ..., -0.2788,  0.0154, -0.4091],\n",
      "          [ 0.0991,  0.1671, -0.2688,  ...,  0.5286, -0.0366, -0.3288]]]])\n"
     ]
    }
   ],
   "source": [
    "print(out_sample.dtype)\n",
    "print(out_sample.shape)\n",
    "print(out_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b93f0c-0086-4b37-8816-a684c17c991a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
